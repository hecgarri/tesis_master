\documentclass[12pt, twoside]{book}\usepackage[]{graphicx}\usepackage[]{color}

\usepackage{alltt}\usepackage[]{graphicx}\usepackage[]{color}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{lscape} %Para seleccionar páginas horizontales 
\usepackage[cc]{titlepic} 
\usepackage[hidelinks]{hyperref}  %Para links ocultos
\usepackage{url} %Para direcciones web
\usepackage[makeroom]{cancel}
\pagestyle{fancy}
\usepackage{multicol} % muchas columnas
\usepackage{booktabs} % midrule, bottomrule
\usepackage{titlesec}
\titlespacing\section{0pt}{12pt plus 4pt minus 2pt}{0pt plus 2pt minus 2pt}
\titlespacing\subsection{0pt}{12pt plus 4pt minus 2pt}{0pt plus 2pt minus 2pt}
\titlespacing\subsubsection{0pt}{12pt plus 4pt minus 2pt}{0pt plus 2pt minus 2pt} 
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\usepackage{blindtext}

\let\bold\boldsymbol
\let\bf\mathbf


\parindent=0pt % Para el uso de sangrías
\parskip=\medskipamount

\fancyhf{}
 \setcounter{page}{1}
%\rfoot{Página \thepage \hspace{1pt} de \pageref{LastPage}}
\setcounter{section}{0}

\usepackage[caption=false]{subfig}
\usepackage{blindtext}  %Texo sin sentido
\usepackage{amsmath} \newenvironment{smatrix}{\left(\begin{smallmatrix}}{\end{smallmatrix}\right)} %SMALL
\usepackage{amsthm}
\usepackage{amsfonts}
\DeclareMathOperator{\sgn}{sgn} %Para formalizar la función signo 
\usepackage{enumerate}
\usepackage{dsfont} %Para usar una indicadora
\numberwithin{equation}{section}
\usepackage{xcolor}
\usepackage[backend=bibtex]{biblatex}
\bibliography{biblio.bib}
\usepackage{booktabs,caption}
\usepackage[flushleft]{threeparttable}


\makeatletter
\newcommand{\distas}[1]{\mathbin{\overset{#1}{\kern\z@\sim}}}%
\newsavebox{\mybox}\newsavebox{\mysim}
\newcommand{\distras}[1]{%
  \savebox{\mybox}{\hbox{\kern3pt$\scriptstyle#1$\kern3pt}}%
  \savebox{\mysim}{\hbox{$\sim$}}%
  \mathbin{\overset{#1}{\kern\z@\resizebox{\wd\mybox}{\ht\mysim}{$\sim$}}}%
}
\makeatother
\usepackage{mdframed} %Para usar recuadros

    \usepackage{framed}

    \colorlet{shadecolor}{blue!15}

    \newtheorem{theorem}{Observación}
    \newenvironment{theo}
      {\begin{shaded}\begin{theorem}}
      {\end{theorem}\end{shaded}}
      \numberwithin{theorem}{section}

\colorlet{shadecolor}{red!15}

    \newtheorem{teorema}{Proposición}
    \newenvironment{teo}
      {\begin{shaded}\begin{teorema}}
      {\end{teorema}\end{shaded}}
      \numberwithin{teorema}{section}

\colorlet{shadecolor}{gray!15}
    \newtheorem{defi}{Definición}
    \newenvironment{defin}
      {\begin{shaded}\begin{defi}}
      {\end{defi}\end{shaded}}
      \numberwithin{defi}{section}
%\newtheorem{rexample}{Código R}[subsection]
\newtheorem{prop}{Proposición}
%\newtheorem{defi}{Definición}
\numberwithin{prop}{section}
\numberwithin{defi}{section}
\theoremstyle{plain}
\setlength{\textfloatsep}{10pt}
\usepackage{multicol}
\usepackage{float}

\usepackage[affil-it]{authblk}
\usepackage{setspace}
\usepackage{listings}

\usepackage{geometry}
\geometry{a4paper, left=3cm, right=3cm, top=3cm, bottom=3cm}
\newcommand*\rfrac[2]{{}^{#1}\!/_{#2}}
\title{Análisis de datos: Transmisión de precios}
\author{H\'ector Garrido Henr\'iquez\thanks{Ingeniero Comercial. Contacto: \texttt{hectorgarridohenriquez@gmail.com}} \\ 
Profesor: Sergio Contreras Espinoza}

\affil{Mag\'ister en Matem\'atica Menci\'on Estad\'istica \\ Universidad del B\'io-B\'io}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}

\allowdisplaybreaks
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
%\SweaveOpts{concordance=TRUE}
\begin{titlepage}
\begin{center}
\includegraphics[scale=0.07]{./figure/logo.png}\\
\textsc{\Large Universidad del Bío-Bío \\[0.5cm] Facultad de Ciencias}\\[1cm] % University name
\textsc{\Large}\\[0.3cm] % Thesis type

\noindent\makebox[\linewidth]{\rule{\textwidth}{1pt}} 
{\huge Transmisi\'on Asim\'etrica de Precios en el sector de la palta en Chile:\\[0.3cm] Evidencia desde un modelo TVECM}\\[0.4cm] % Thesis title
\noindent\makebox[\linewidth]{\rule{\textwidth}{1pt}} 

\textsc{\Large}\\[0.5cm] % Thesis type

\begin{minipage}{0.45\textwidth}
\begin{flushleft} \large
\emph{Autor:}\\
Héctor Garrido Henríquez % Author name - remove the \href bracket to remove the link
\end{flushleft}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\begin{flushleft} \large
\emph{Profesor(es) Guía(s):} \\
Dr. Sergio Contreras Espinoza \\ Dra. Monia Ben Kaabia 
\end{flushleft}
\end{minipage}\\[2cm]
 
\large \textit{Tesis para optar al grado de Magíster en Matemática con mención en Estadística}\\[0.3cm] % University requirement text
\textit{}\\[0.4cm]
\ Departamento de Estadística \\
[0.4cm]\ Departamento de Matemática
\\[1cm] % Research group name and department name
 
{\large \today}\\[2cm] % Date
%\includegraphics{Logo} % University/department logo - uncomment to place it
 
%\vfill
\end{center}

\end{titlepage}
\newpage



\tableofcontents

\listoffigures
\listoftables
\onehalfspacing
\chapter*{Agradecimientos}
\chapter*{Abstract}
\chapter{Introducción}
\section{introducción}

\chapter{Escenario de la industria en Chile}


\chapter{Modelos y contrastes estadísticos utilizados en esta tesis}


\section{Contrastes de raíz unitaria/estacionariedad}
\subsection{Contraste de Dickey-Fuller Aumentado}

El contraste más utilizado en la investigación aplicada, dada su simplicidad, es el contraste propuesto por \cite{fuller1976} y \cite{dickey1981}. Para aplicar este contraste existen dos posibles modelos 

Si $y_{t}$ satisface la siguiente ecuación

\begin{equation}
y_{t} = \alpha+\rho y_{t-1}+\epsilon_{t}\qquad (t=1,...,n)
\end{equation}
Donde $\epsilon_{t}\sim \mathcal{N}(0,\sigma^{2})$. 

Si $y_{t}$ satisface la siguiente ecuación 

Como puede observarse en el cuadro \ref{tab-1}, existen 3 estadísticos, $\Phi_{1},\quad \Phi_{2}$ y $\Phi_{3}$, y sus respectivas hipótesis que pueden ser utilizados. Mientras $\Phi_{1}$
\begin{equation}
y_{t} = \alpha+\beta\left(t-1-\frac{1}{2}n\right)+\rho y_{t-1}+\epsilon_{t}\qquad (t=1,...,n)
\end{equation}
Donde $\epsilon_{t}\sim \mathcal{N}(0,\sigma^{2})$. 

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Hipótesis del contraste de Dickey-Fuller}
\begin{tabular}{@{}llrllll@{}}
\toprule
\multicolumn{2}{l}{Estadístico} & \multicolumn{2}{c}{$\mathcal{H}_{0}$} &
\multicolumn{2}{c}{$\mathcal{H}_{a}$} \\
\cmidrule(l){3-4} \cmidrule(l){5-6} \\
\multicolumn{2}{l}{$\tau$} & 
\multicolumn{2}{l}{$\rho =1 $} & 
\multicolumn{2}{l}{$\rho =0 $} \\
\multicolumn{2}{l}{$\Phi_{1}$} &
\multicolumn{2}{l}{$(\alpha,\rho)=(0,1)$} &
\multicolumn{2}{l}{$(\alpha,\rho)\neq(0,1)$} \\
\multicolumn{2}{l}{$\Phi_{2}$} &
\multicolumn{2}{l}{$(\alpha,\beta, \rho)=(0,0,1)$} &
\multicolumn{2}{l}{$(\alpha,\beta,\rho)\neq(0,0,1)$} \\
\multicolumn{2}{l}{$\Phi_{3}$} &
\multicolumn{2}{l}{$(\alpha,\beta, \rho)=(\alpha,0,1)$} &
\multicolumn{2}{l}{$(\alpha,\beta,\rho)\neq(\alpha,0,1)$} \\
\bottomrule
\end{tabular}
\label{tab-1}
\begin{tablenotes}
\small
\item Fuente: Elaboración propia basado en Dickey y Fuller (1981)
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Contraste de Phillips Perron (1992)}

De manera similar al contraste anterior \cite{phillips1988} proponen un contraste no paramétrico para la hipótesis nula de raíz unitaria. A diferencia del contraste de Dickey Fuller este contraste resiste dependencia débil y heteroscedasticidad del término de error. El contraste está construido sobre la base de las siguientes formas funcionales: 

\begin{align}
y_{t} & = \mu+\alpha y_{t-1}+\varepsilon_{t}, \\ 
y_{t} & = \mu+\beta\left(t-\frac{1}{2}T\right)+\alpha y_{t-1}+\varepsilon_{t}
\end{align}

Luego de esto definen los siguientes estadísticos de prueba: 
\begin{align}
Z(\hat{\alpha}) & = T(\hat{\alpha}-1)-\hat{\lambda}/\bar{m}_{yy}, \label{eq:pp1}\\ 
Z(\tau_{\hat{\alpha}}) & = (\hat{s}/\hat{\sigma}T_{l})t_{\hat{\alpha}}-\hat{\lambda}'\hat{\sigma}T_{l}/\bar{m}^{1/2}_{yy}, \\ 
Z(\tau_{\hat{\mu}}) & = (\hat{s}/\hat{\sigma}_{Tl})t_{\hat{\mu}}+\hat{\lambda}'\hat{\sigma}_{Tl}m_{y}/\bar{m}^{1/2}_{yy}m^{1/2}_{yy} \label{eq:pp3}
\end{align}

Donde $\bar{m}_{yy}=T^{-2}\sum (y_{t}-\bar{y})^{2}$, $m_{yy}=T^{-2}\sum y_{t}^{2}$, $m_{y}=T^{-3/2}\sum y_{t}$ y $\hat{\lambda} = \frac{1}{2}(\hat{\sigma}^{2}_{Tl}-\hat{s} ^{2})$, donde $\hat{\sigma}^{2}$ es la varianza muestral de los residuos, $\hat{\lambda}'=\hat{\lambda}/\hat{\sigma}^{2}_{Tl}$. Luego, la varianza de largo plazo es estimada de la siguiente forma: 
\begin{equation}
\hat{\sigma}^{2}_{Tl}=T^{-1}\sum_{t=1}^{T}\hat{\varepsilon}_{t}^{2}+2T^{-1}\sum_{s=1}^{l}w_{sl}\sum_{t=s+1}^{T}\hat{\varepsilon}_{t}\hat{\varepsilon}_{t-s}
\end{equation}
Donde $w_{sl}=1-s/(l+1)$

De manera similar, el contraste permite la inclusión de una tendencia determinista, modificando los estadísticos de prueba de la siguiente manera: 
\begin{align}
Z(\tilde{\alpha})  & = T(\hat{\alpha}-1)-\hat{\lambda}/M, \\ 
Z(t_{\tilde{\alpha}}) & = (\tilde{s}/\tilde{\sigma}_{Tl})t_{\tilde{\alpha}}-\tilde{\lambda}'\tilde{\sigma}_{Tl}/M^{1/2}, \\ 
Z(t_{\tilde{\mu}}) & = (\tilde{s}/\tilde{\sigma}_{Tl})t_{\tilde{\mu}}-\tilde{\lambda}'\tilde{\sigma}_{Tl}m_{y}/M^{1/2}(M+m_{y}^{2})^{1/2}, \\
Z(t_{\tilde{\beta}}) & = (\tilde{s}/\tilde{\sigma}_{Tl})t_{\tilde{\beta}}-\tilde{\lambda}'\tilde{\sigma}_{Tl}\left(\frac{1}{2}m_{y}-m_{ty}\right)/(M/12)^{1/2}\bar{m}_{yy}^{1/2}
\end{align}

Donde $m_{y}$, $\bar{m}_{yy}$, $\tilde{\lambda}$, $\tilde{\lambda}'$ y $\tilde{\sigma}_{Tl}$ son definidos al igual que en las ecuaciones \ref{eq:pp1} a \ref{eq:pp3} y $m_{ty}=T^{5/2}\sum t_{yt}$, $t_{\tilde{\mu}}$, $t_{\tilde{\beta}}$ y $t_{\tilde{\alpha}}$ son los estadísticos $t$ de $\tilde{\mu}$, $\tilde{\alpha}$ y $\tilde{\beta}$, respectivamente. Por último la constante $M=(1-T^{-2})m_{yy}-12m^{2}_{ty}+12(1+T^{-1})m_{ty}m_{y}-(4+6T^{-1}+2T^{-2})m_{y}^{2}$

\subsection{Contraste de Elliot, Rothenberg \& Stock (1996)} 

Un defecto de los contrastes de raíz unitaria recién expuestos es su baja potencia si el verdadero proceso generador de datos es AR(1) cuyo coeficiente sea cercano a uno. Para mejorar la potencia de estos contrastes, Elliott, Rothenberg \& Stock (1996) propusieron quitar los términos deterministas de lae  serie de tiempo. Los autores desarrollaron unos contrastes de punto-óptimo factible, denotados por $P^{\mu}_{T}$ y $P^{\tau}_{T}$, los cuales toman en cuenta posibles problemas de autocorrelación en el término de error. El segundo contraste es denotado omo el $DF-GLS$, el cual consiste en una modificación del contraste de Dickey-Fuller Aumentado. Se asume la siguiente forma para el proceso generador de los datos: 

\begin{align}
y_{t} & = d_{t}+u_{t} \label{eq:ers1}\\ 
u_{t} & = a u_{t-1}+v_{t} \label{eq:ers2}
\end{align}

Donde $d_{t}=\boldsymbol{\beta' z_{t}}$ representa a los componentes determinísticos, $v_{t}$ es un proceso de error estacionario de media cero. En el caso en que $a=1$, las ecuaciones  \ref{eq:ers1} y \ref{eq:ers2} implican que el proceso es I(1), mientras que si $|a|<1$ significa que la serie es estacionaria. 

Entonces el estadístico de punto óptimo factible será 

\begin{equation}
P_{T} = \frac{S(a=\bar{a})-\bar{a}S(a=1)}{\hat{\omega}^{2}}
\end{equation}

Donde $S(a=\bar{a})$y $S(a=1)$ son las sumas de cuadrados residuales de una regresión de mínimos cuadradosd de $y_{a}$ sobre $Z_{a}$ con 

\begin{align}
y_{a} & = (y_{1}, y_{2}-a y_{1},...,y_{T}-ay_{T-1}), \\
\boldsymbol{Z_{a}} & = (\boldsymbol{z_{1},z_{2}-a z_{1},..., z_{T}-a z_{T-1}})
\end{align}

Por lo tanto, $y_{a}$ es un vector columna $T-dimensional$ y $\boldsymbol{Z_{a}}$ defin una matriz de dimensiones $T\times q$. El estimador para la varianza del proceso de error $v_{t}$ puede ser estimado como 

\begin{equation}
\hat{\omega} = \frac{\hat{\sigma}^{2}_{v}}{(1-\sum_{i=1}^{p}\hat{a}^{i})^{2}}
\end{equation}

Donde $\hat{\sigma}^{2}_{v}$ y $\hat{a}_{i}$ para $i=1,..,p$ son tomados desde la regresión de mínimos cuadrados auxiliar. 

\begin{equation}
\Delta y_{t} = a_{0}+a_{1}\Delta y_{t-1}+...+\Delta y_{t-p}+a_{p+1}+v_{t}
\end{equation}

Finalmente, la cantidad escalar $\bar{a}$ es fijada como $\bar{a}=1+\frac{\bar{c}}{T}$, donde $\bar{c}$ denota una constante. Dependiendo de los términos deteministas incluidos originalmente, el valor de $\bar{c}$ será -7 para el caso de una constante, mientras que será de -13.5 en el caso de que se presente una tendencia lineal. 

A continuación Elliot et al (1996) han propuesto otro contraste basado en el contrase de Dickey Fuller, el cuál es un estadístico para probar $\alpha_{0}=0$ basados en el siguiente modelo. 

\begin{equation}
\Delta y_{t}^{d} = \alpha_{0}y_{t-1}^{d}+\alpha_{1}\Delta _{t-1}^{d}+...+\alpha_{p}\Delta _{t-p}^{d}+\varepsilon_{t}
\end{equation}

Donde $y_{t}^{d}$ son los residuos en la regresión auxiliar $y_{t}^{d}\equiv y_{t}-\boldsymbol{\hat{\beta}z_{t}}.$  

\subsection{Contraste Kiatkowsky, Pesaran, Schmidt \& Shin (1992)}

Este contraste está pensando para detectar ya sea estacionariedad en tendencia o en nivel. A diferencia de los contrastes anteriores donde la hipótesis nula implicaba afirmar la presencia de una raíz unitaria, en este caso, la hipótesis nula dice relación con que el proceso sea estacionario. Para construir el contraste se considera el siguiente modelo de base: 

\begin{align}
y_{t} & = \zeta t+r_{t}+\varepsilon_{t} \\  
r_{t} & = r_{t-1}+u_{t}
\end{align}

Donde $r_{t}$ es una caminata aleatoria y el término de error se asume i.i.d $(0,\sigma^{2}_{u})$. La hipótesis nula de este contraste consiste en afirmar que $\mathcal{H}_{0}: \sigma^{2}_{u}=0$, en cuyo caso, la tendencia $r_{t}$ sería igualmente una tendencia determinista en lugar de estocástica. 

Para construir el estadístico de prueba se sigue el siguiente procedimiento: i) se realiza una regresión de $y_{t}$ sobre una constante o bien sobre una tendencia lineal y una constante, dependiendo de si se desea contrastar la hipótesis de estacionariedad en nivel o en pendiente. Luego se calcula la suma parcial de los residuos $\hat{\varepsilon}_{t}$ de la regresión como 

\begin{equation}
S_{t} = \sum_{i=1}^{t}\hat{\varepsilon}_{i}, \qquad t=1,2,...,T
\end{equation}

El estadístico de prueba está definido como 

\begin{equation}
LM  = \frac{\sum_{t=1}^{T}S_{t}^{2}}{\hat{\sigma}^{2}_{\varepsilon}}
\end{equation}

Donde $\hat{\sigma}^{2}_{\varepsilon}$ es una estimación de la varianza del error a un paso. Los autores sugieren utiliza una ventana de Bartlett $w(s,l)=1-s/(l+1)$ como una función que da un peso optimo para calcular la varianza de largo plazo, esto es

\begin{equation}
\hat{\sigma}^{2}_{\varepsilon} = s^{2}(l)=T^{-1}\sum_{t=1}^{T}\hat{\varepsilon}^{2}_{t}+2T-1\sum_{s=1}^{l}1-\frac{s}{l+1}\sum_{t=s+1}^{T}\hat{\varepsilon}_{t}\hat{\varepsilon}_{t-1}
\end{equation}



\section{Análisis de cointegración}
\subsection{Cointegración y análisis de las relaciones de largo plazo}
{\color{red} \textbf{Apuntes de Farías (2017a)}

Dutoit et al. (2010, p. 15) define la transmi-
sión en este contexto como “(...) la relación
entre los precios de dos mercados relacio-
nados; por ejemplo, entre el precio interna-
cional de un producto y su precio doméstico

En econometría, la estimación de las re-
laciones entre variables que presentan
tendencia reviste complejidad, porque su
estructura puede provocar que se consi-
deren significativas relaciones comple-
tamente espurias (Granger y Newbold,
1974)

Estas técnicas (cointegración) corresponden
a los modelos de cointegración, que en la
actualidad son utilizados con frecuencia en
los estudios de transmisión de precios (aná-
lisis horizontal) y de transferencia de costos
(análisis vertical)


En este caso, $\boldsymbol{\Pi}$ pue-
de ser factorizado en una matriz $\boldsymbol{\alpha\beta'}$, donde
$\boldsymbol{\alpha}$ es una matriz de dimensión $n \times r$ que re-
presenta la velocidad de ajuste al equilibro,
mientras que $\boldsymbol{\beta}$ es una matriz de dimensión
$n \times r$ que representa los coeficientes de largo
plazo

{\color{red} \textbf{Apuntes de Juselius}

\begin{itemize}
\item The time series describing cumulated trend-adjusted shocks is usually called a stochas-
tic trend. It is a cumulation of random shocks with zero mean and constant variance. If
\item with a linear deterministic trend component. Thus, the difference between a stochastic
and deterministic trend is that the increments of a stochastic trend change randomly,
whereas those of a deterministic trend are constant over time.
\item It is easy to see that if inflation rate is I(1) with a non-zero mean, then prices will contain
a integrated twice cumulated of order stochastic two, or in trend, 
t
 s=1 notation
i=1 s
 i . pt We  say I(2).
 that trend-adjusted prices are
\item We shall argue below that, unless a unit root is given a structural interpretation, the
choice of one representation or the other is as such not very important, as long as there is
consistency between the economic analysis and the choice. However, from an econometric
point of view the choice between the two representations is usually crucial for the whole
empirical analysis and should therefore be carefully considered.
\item variable.
Because a cointegrating relation does not necessarily correspond to an interpretable
economic relation, we make a further distinction between the statistical concept of a
‘cointegration relation’ and the economic concept of a ‘long-run equilibrium relation’.
\item say second that stochastic the distinction trend,
 between 
 u2i , as a long-run a long-run and structural medium-run trend stochastic or not. trend Thus,in one this might
 case
is between an I(1) stochastic trend with no linear trend and a near I(1) stochastic trend
with a linear trend.

\end{itemize}

\begin{defin}
Sea $\{\bold{x}_{t}\}$ un proceso estocástico para $t=..., -1,0,1,2,...$ Si 

\begin{align}
\mathbb{E}[\bold{x}_{t}] & =-\infty < \bold{\mu} <\infty \\ 
\mathbb{E}[\bold{x}_{t}-\bold{\mu}]^{2} & = \bold{\Sigma}_{0}<\infty \qquad \forall t\\ 
\mathbb{E}[(\bold{x}_{t}-\bold{\mu})(\bold{x}_{t+h}-\bold{\mu})] & = \bold{\Sigma}_{h} \qquad \forall \text{t y h}
\end{align}
Entonces $\bold{x}_{t}$ es \textit{debilmente estacionario}. La estacionariedad estricta requiere que la distribución de $(x_{t1},...,x_{tk})$ es la misma que $(x_{t1+h},...,x_{tk+h})$ para $h=...,-1,0,1,2,...$
\end{defin}

for time t based on the available information at time $t_1$. For example, a VAR model
with autocorrelated and or heteroscedastic residuals would describe agents that do not
use all information in the data as efficiently as possible. This is because by including the

 For example, a VAR model
with autocorrelated and or heteroscedastic residuals would describe agents that do not
use all information in the data as efficiently as possible. 

Simulation studies have shown that valid statistical inference is sensitive to violation
of some of the assumptions, such as parameter non-constancy, autocorrelated residu-
als (the higher, the worse) and skewed residuals, while quite robust to others, such as
excess kurtosis and residual heteroscedasticity. This will be discussed in more detail in


• the use of intervention dummies to account for significant political or institutional
events during the sample;
• conditioning on weakly or strongly exogenous variables;
• checking the measurements of the chosen variables;
• changing the sample period to avoid fundamental regime shift or splitting the sample
into more homogenous periods.

and the model has been extended to contain Dt , a vector of deterministic components,
such as a constant, seasonal dummies and intervention dummies. The autoregressive for-
mulation is useful for expressing hypotheses on economic behaviour, whereas the moving average representation is useful when examining the properties of the proces.

Si asumimos un modelo $VAR(2)$ bi-dimensional

\begin{equation}
(\bold{I}-\boldsymbol{\Pi}_{1}L-\boldsymbol{\Pi}_{2}L^{2})\bold{x}_{t} = \boldsymbol{\Phi}\bold{D}_{t}+\bold{\varepsilon}_{t}
\end{equation}

La función características es entonces 

\begin{align}
\bold{\Pi}(z) & = \bold{I}-\left[\begin{array}{cc} 
\pi_{1.11} & \pi_{1.12} \\
\pi_{1.21} & \pi_{1.22}
\end{array}\right]z- \left[\begin{array}{cc} 
\pi_{2.11} & \pi_{2.12} \\
\pi_{2.21} & \pi_{2.22}
\end{array}\right]z^{2} \\
              & = \bold{I}-\left[\begin{array}{cc} 
\pi_{1.11}z & \pi_{1.12}z \\
\pi_{1.21}z & \pi_{1.22}z
\end{array}\right]- \left[\begin{array}{cc} 
\pi_{2.11}z^{2} & \pi_{2.12}z^{2} \\
\pi_{2.21}z^{2} & \pi_{2.22}z^{2}
\end{array}\right] \\
 & = \left[\begin{array}{cc} (1-\pi_{1.11}z-\pi_{2.11}z^{2}) & (-\pi_{1.12}z-\pi_{2.12}z^{2}) \\ 
 (-\pi_{1.21}z-\pi_{2.21}z^{2}) & (1-\pi_{1.22}z-\pi_{2.22}z^{2})
 \end{array}\right]
\end{align}
y 

\begin{align}
|\boldsymbol{\Pi}(z)| & = (1-\pi_{1.11}z-\pi_{2.11}z^{2})(1-\pi_{1.22}z-\pi_{2.22}z^{2})-(\pi_{1.12}z+\pi_{2.12}z^{2})(\pi_{1.21}z+\pi_{2.21}z^{2}) \\ 
& = 1-a_{1}z-a_{2}z^{2}-a_{3}z^{3}-a_{4}z^{4} \\ 
& = (1-\rho_{1}z)(1-\rho_{2}z)(1-\rho_{3}z)(1-\rho_{4}z)
\end{align}

El determinante entrega información valiosa sobre el comportamiento dinámico del proceso. 

Luego 

\begin{align}
\bold{x}_{t} & = \frac{\boldsymbol{\Pi}^{a}(L)(\boldsymbol{\Phi}\bold{D}_{t}+\varepsilon_{t})}{(1-\rho_{1}z)(1-\rho_{2}z)(1-\rho_{3}z)(1-\rho_{4}z)}+\tilde{\bold{X}}^{0}, \qquad t=1,...,T \\ 
& = \left(\frac{\bold{\Pi}_{1}^{a}L+\bold{\Pi}^{a}_{2}L^{2}}{(1-\rho_{2}z)(1-\rho_{3}z)(1-\rho_{4}z)}\right)\left(\frac{\varepsilon_{t}+\bold{\Phi}D_{t}}{(1-\rho_{1}L)}\right)+\bold{\tilde{X}}^{0}, \qquad t=1,...,T
\end{align}

\section{Estimación basada en la verosimilitud para el modelo VAR irrestricto}

Cuando el modelo no tiene restricciones sobre sus parámetros (como las que pueden surgir debido a la presencia de raíces unitarias) el modelo puede estimarse por MCO, caso que coincide con el estimador de \textit{Full information maximum likelihood}

Si escribimos el modelo en su versión apilada
\begin{align}
& \bold{x}_{t} = \bold{B'Z}_{t}+\varepsilon_{t}, \qquad t=1,..,T \\ 
& \varepsilon_{t}\sim IN_{p}(\bold{0,\Omega})
\end{align}

Donde: 
\begin{itemize}
\item $\bold{B'}=\left[\boldsymbol{\mu_{0}, \Pi_{1}, \Pi_{2},...,\Pi_{k}}\right]$
\item $\bold{Z'}_{t} = \left[\bold{1,x'_{t-1}, x'_{t-2},...,x'_{t-k}}\right]$
\item $\bold{X}^{0} = \left[\bold{x'_{0}, x'_{-1},...,x'_{-k+1}}\right]$ 
\end{itemize}

La función de verosimilitud será la siguiente: 

\begin{equation}
\log L(\boldsymbol{B,\Omega,X}) = -T\frac{p}{2}\log(2\pi)-T\frac{1}{2}\log|\bold{\Omega}|-\frac{1}{2}\sum_{t=1}^{T}(\bold{x_{t}-B'Z_{t}})'\boldsymbol{\Omega}^{-1}(\bold{x_{t}-B'Z_{t}})
\end{equation}

Si calculamos $\frac{\partial \log L}{\partial \bold{B}}$, tendremos
\begin{equation*}
\sum_{t=1}^{T}\bold{x_{t}Z'_{t}} = \bold{\tilde{B}'}\sum_{t=1}^{T}\bold{Z_{t}Z_{t}'}
\end{equation*}

Entonces, el estimador de máxima verosimilitud es 

\begin{equation}
\bold{\tilde{B}}' = \sum_{t=1}^{T}(\bold{x_{t}Z'_{t}})\left(\sum_{t=1}^{T}\bold{Z_{t}Z'_{t}}\right)^{-1} = \bold{M}_{xZ}\bold{M}_{ZZ}^{-1}
\end{equation}

Luego calculando $\frac{\partial \log L}{\partial \boldsymbol{\Omega}}=\bold{0}$

\begin{equation}
\boldsymbol{\hat{\Omega}} = T^{-1}\sum_{t=1}^{T}(\bold{x_{t}-\hat{B}'Z_{t}})(\bold{x_{t}-\hat{B}'Z_{t}})' = T^{-1}\sum_{t=1}^{T}\boldsymbol{\hat{\varepsilon}_{t}\hat{\varepsilon}'_{t}}
\end{equation}

El valor máximo de la función de Verosimilitud, será el siguiente: 

\begin{equation}
\log L _{\max} = -\frac{P}{2}T\log (2\pi)-\frac{1}{2}T\log|\boldsymbol{\hat{\Omega}}|-\frac{1}{2}\sum_{t=1}^{T}(\bold{x_{t}-\hat{B}'Z_{t}})'\boldsymbol{\hat{\Omega}}^{-1}(\bold{x_{t}-\hat{B}'Z_{t}}) 
\end{equation}

Mostraremos que $\log L_{\max} = -\frac{1}{2}T\log |\boldsymbol{\hat{\Omega}}|+K, \qquad K\in \mathbb{R}$

\begin{align}
(\boldsymbol{x_{t}-\hat{B}'Z_{t}})\boldsymbol{\hat{\Omega}}^{-1}(\bold{x_{t}-\hat{B}'Z_{t}}) 
& = \boldsymbol{\hat{\varepsilon}'_{t}\boldsymbol{\hat{\Omega}}^{-1}\hat{\varepsilon}_{t}} \nonumber \\
& = \sum_{ij}\hat{\varepsilon}_{t,i}(\boldsymbol{\hat{\Omega}}^{-1})_{ij}\hat{\varepsilon}_{t,j} \\
& = \sum_{ij}(\boldsymbol{\hat{\Omega}}^{-1})_{ij}\hat{\varepsilon}_{t,i}\hat{\varepsilon}_{t,j} \nonumber \\ 
& = \text{traza}\{\boldsymbol{\hat{\Omega}}^{-1}\boldsymbol{\hat{\varepsilon_{t}}\hat{\varepsilon}'_{t}}\}
\end{align}

Luego, se tiene que 

\begin{align}
\sum_{t=1}^{T}(\bold{x_{t}-\hat{B}'Z_{t}})\boldsymbol{\hat{\Omega}}^{-1}(\bold{x_{t}-\hat{B}'Z_{t}})' & = \sum_{t=1}^{T}\text{traza}\{\boldsymbol{\hat{\Omega}}^{-1}\boldsymbol{\hat{\varepsilon_{t}}\hat{\varepsilon}'_{t}}\} \\
& = T \sum_{t=1}^{T}\text{traza}\{\boldsymbol{\hat{\Omega}}^{-1}\boldsymbol{\hat{\varepsilon_{t}}\hat{\varepsilon}'_{t}}/T\} \\ 
& = T \text{traza}\{\boldsymbol{\hat{\Omega}}^{-1}\hat{\Omega}\} \\ 
& = T \text{traza}\{\bold{I}_{p}\} = Tp
\end{align}

De donde se desprende que 

\begin{equation}
\log L_{\max} = -T \frac{1}{2} \log |\boldsymbol{\hat{\Omega}}|\underbrace{-T\frac{p}{2}-T\frac{p}{2}\log(2\pi)}_{+K}
\end{equation}

\textbf{NOTA PARA RECORDAR: si las variables del modelo están formuladas en logaritmo la desviación estándar de cada una de estas puede ser interpretada como un porcentaje de error }


\subsection{Contraste de razón de verosimilitud}

\begin{equation}
  -2\log Q(\mathcal{H}_{k}/\mathcal{H}_{k+1}) =  T(\log|\boldsymbol{\hat{\Omega}}_{k}|-\log|\boldsymbol{\hat{\Omega}}_{k+1}|) \sim \chi^{2}_{p^{2}}
\end{equation}


Criterios de selección 

\begin{align}
\text{AIC} & = \log |\boldsymbol{\hat{\Omega}}|+(p^{2}k)\frac{2}{T} \\ 
\text{SC} & = \log|\boldsymbol{\hat{\Omega}}|+(p^{2}k)\frac{\log T}{T} \\ 
\text{Hannah-Quinn} & = \log|\boldsymbol{\hat{\Omega}}|+(p^{2}k)\frac{2\log \log T}{T}
\end{align}

Todos los criterios en común están basados en el máximo valor que alcanza la función de verosimilitud del modelo, más un factor que penaliza por el número de parámetros estimados. 

\textbf{
Al momento de la determinación del número de rezagos, volver a revisar tabla 4.5 de la página 92}

\begin{equation}
\text{Trace correlation} = 1-\text{traza}(\boldsymbol{\hat{\Omega}}[\text{Cov}(\bold{\Delta x_{t}})]^{-1})/p 
\end{equation}


\subsubsection{El contraste de Ljung-Box}

\begin{equation}
\text{Ljung-Box} = T(T+2)\sum_{h=1}^{T/4}(T-h)^{-1}\text{traza}(\boldsymbol{\hat{\Omega}'_{h}\hat{\Omega}^{-1}\hat{\Omega}'_{h}\hat{\Omega}^{-1}})
\end{equation}

Donde  $ \boldsymbol{\hat{\Omega}}_{h} = T^{-1}\sum_{t=1}^{T}\boldsymbol{\hat{\varepsilon}_{t}\hat{\varepsilon}_{t-h}'}$. El estadístico se considera distribuido aproximadamente según una $\chi^{2}$ con $p^{2}(T/4-k+1)-p^{2}$ grados de libertad. 

También puede utilizarse un contraste propuesto por Godfrey(1988),  el cual consiste en regresar los residuos del modelo VAR estimado, $\boldsymbol{\hat{\varepsilon}_{t}}$, sobre $k$ variables rezagadas, $\bold{x_{t-1}, x_{t-2}, ...,x_{t-k}}$ y el $j$-ésimo residuo rezagado
\begin{equation}
\boldsymbol{\hat{\varepsilon}_{t}}=\bold{A_{1}x_{t-1}+A_{2}x_{t-2}+...+A_{k}x_{t-k}+A_{\varepsilon}}\boldsymbol{\hat{\varepsilon}}
\end{equation}

Donde los primeros $j$ valores están perdidos $\hat{\varepsilon}_{-j},...,\hat{\varepsilon}_{-1}$, los que son fijados a cero. El Estadístico de prueba, de tipo multiplicador de Lagrange es calculado de la siguiente forma 

\begin{equation}
LM(j) = -(T-p(k+1)-\frac{1}{2})\log \left(\frac{|\boldsymbol{\tilde{\Omega}}(j)|}{||\boldsymbol{\tilde{\Omega}}}\right)
\end{equation}

El estadístico se distribuye aproximadamente como una $\chi^{2}$ con $p^{2}$ grados de libertad. Porque 

\subsubsection{Contrastes para Heteroscedasticidad Residual}

El contraste ARCH $m$-ésimo es calculado como $(T+k-m)\times R^{2}$. Aquí $R^{2}$ se obtiene de la siguiente regresión auxiliar

\begin{equation}
\hat{\varepsilon}^{2}_{i,t} = \gamma_{0}+\sum_{j=1}^{m}\gamma_{j}\hat{\varepsilon}_{i,t-j}^{2}+error
\end{equation}

El estadístico se distribuye aproximadamente como una $\chi^{2}$ con $m$ grados de libertad. 

\subsubsection{Contrastes de normalidad}

Para construir un contraste adecuado para verificar la hipótesis de normalidad (multivariada) de los residuos del modelo, se utiliza lo siguiente

\begin{align}
\text{skewness}_{i} & = \sqrt{\hat{b}_{1i}} = T^{-1}\sum_{t=1}^{T}(\hat{\varepsilon}_{i}/\hat{\sigma}_{i})^{3}_{t} \\ 
\text{kurtosis}_{i} & = \hat{b}_{2i} = T^{-1}\sum_{t=1}^{T}(\hat{\varepsilon}_{i}/\hat{\sigma}_{i})^{4}_{t} 
\end{align}

Bajo el supuesto de que los residuos se distribuyen normal, el skewness y la kurtosis de los residuos $\hat{\varepsilon}_{i}$ son asintóticamente normales con las siguientes medias y varianza

\begin{equation}
\sqrt{T}(\text{skewness}_{i}-0)\distas{a} \mathcal{N}(0,6)
\end{equation}

y 

\begin{equation}
\sqrt{T}(\text{kurtosis}_{i}-3)\distas{a}\mathcal{N}(0,24)
\end{equation}

Entonces, la varianza de skewness es más pequeña que la varianza de la kurtosis, lo cual significa que los contrastes de normalidad son más sensibles a desviaciones sobre el supuesto de skewness (a menudo como resultado de los outliers) que por el exceso de kurtosis (las colas pesadas o demasiados residuos cercanos a la media). Basado en lo anterior, se puede construir un contraste para normalidad univariada de la siguiente forma 


}

\subsection{Modelo Vectorial de Corrección del Error (VECM)}
Suponga que  cada componente de una serie de tiempo $K$-dimensional $y_{t}$ es $I(1)$. Entonces, la ecuación (VAR) no será una formulación adecuada de este modelo debido a que los términos $y_{t},y_{t-1},...,y_{t-p}$ son todos no estacionarios. De todas formas, sustituyendo 
\begin{align}
\bf{A}_{1} & = \bf{I}_{k}+\bold{\Gamma}_{1} \\ 
\bf{A}_{i} & = \bold{\Gamma_{i}}-\bold{\Gamma_{i-1}} \qquad i=1,...,p-1 \\ 
\bf{A}_{p} & = -\bold{\Gamma}_{p-1}
\end{align}

En la ecuación (2.8), reagrupando términos y utilizando que $\Delta \bf{y}_{i} = \bf{y}_{i}-\bf{y}_{i-1}\quad \forall i$, podemos reescribir esta ecuación como 
\begin{equation}\label{vecm1}
\Delta \bf{y}_{t}=\bold{\mu}+\bold{\Gamma}_{1}\Delta \bf{y}_{t-1}+\bold{\Gamma}_{2}\Delta \bf{y}_{t-2}+...+\bold{\Gamma}_{p-1}\Delta \bf{y}_{t-p+1}+\bf{u}_{t}
\end{equation} 
Naturalmente, ambas ecuaciones describen el mismo modelo, pero preferimos usar la ecuación \eqref{vecm1} cuando $\bf{y}_{t}$ es $I(1)$, debido a que cada término es estacionario en este caso. Entonces, cuando $\bf{y}_{t}$ es $I(1)$, podemos encontrar un modelo apropiado para $y_{t}$ diferenciando cada componente de $\bf{y}_{t}$ una vez, y llevando a cabo la regresión basada en la ecuación \eqref{vecm1}. De todas formas, entonces no podremos tomar en cuenta que podría haber dependencias entre algunos de los componentes de $\bf{y}_{t}$. Por ejemplo, dos de los componentes podrían tener una tendencia en común, o podría existir una combinación lineal de los componente de $y_{t}$ la cual fuera estacionaria. Este problema suele resolverse utilizando incluyendo un \textbf{término de corrección del error} $\bold{\Pi}\bf{y}_{t-1}$ en la ecuación \eqref{vecm1}, donde $\bold{\Pi}$ es una matriz $K\times K$ de cuyo rango $rank(\bold{\Pi})<K$, debido a que si $\bold{\Pi}$ tuviera rango completo, entonces $\bold{\Pi}$  es invertible, de manera que la variable no estacionaria $\bf{y}_{t-1}$ puede ser escrita como la suma de términos estacionarios, lo que es una contradicción. Entonces, $rank(\bold{\Pi})=r<K$ lo cual implica que existen $(K\times r)-matrices$ $\boldsymbol{\alpha}$ y $\boldsymbol{\beta}$ de rango $r$ tales que $\bold{\Pi}=\boldsymbol{\alpha}\boldsymbol{\beta}'$. Entonces, cada una de las $r$ filas de $\boldsymbol{\beta}'\bf{y_{t-1}}$ es una combinación lineal estacionaria de los componentes de $y_{t}$ y es llamada una \textbf{relación de cointegración}. El número $r$, el cual es igual al número de relación de cointegración es llamado el \textbf{rango de cointegración}. Como la matriz $\boldsymbol{\beta}$ contiene todos los coeficiente de las relaciones de cointegración, es llamada \textbf{la matriz de cointegración}. La matriz $\boldsymbol{\alpha}$, la cual es la matriz de coeficientes de los términos estacionarios $\boldsymbol{\beta}'\bf{y_{t-1}}$ en la ecuación \eqref{vecm2}, es llamada la matriz de carga. 
\begin{defin}
Un modelo \textbf{VECM} de orden $p$ se define como 
\begin{equation}\label{vecm2}
\Delta \bf{y}_{t}=\boldsymbol{\mu}+\boldsymbol{\alpha\beta}'
\bf{y}_{t-1}+\bold{\Gamma}_{1}\Delta \bf{y}_{t-1}+...+\bold{\Gamma}_{p-1}\Delta \bf{y}_{t-p+1}+u_{t} \quad t=1,...,T
\end{equation}
Donde $\bf{y}_{t}=\left[y_{1t},...,y_{Kt}\right]'$ es un vector aleatorio de $K\times 1$, $\boldsymbol{\mu}$ es un vector constante de $(K\times 1)$, $\boldsymbol{\alpha}$ y $\boldsymbol{\beta}$ son matrices $(K\times r)$ tales que $rank(\boldsymbol{\alpha})=rank(\boldsymbol{\beta})<K$, 
\end{defin} 

\subsection{El contraste de cointegración de Johansen}

Considere el siguiente modelo 

\begin{equation}
\Delta \bf{y}_{t} = \Pi \bf{y}_{t-1}+\Gamma_{1}\Delta\bf{y}_{t-1}+...+\Gamma_{p-1}\Delta\bf{y}_{t-p+1}+u_{t}
\end{equation}

Donde $\bf{y}_{t}$ es un proceso $K$-dimensional y $rk(\Pi)=r$ con  $0\leq r\leq K$. 

\begin{align}
\mathcal{H}_{0}: rk(\bold{\Pi})=r_{0} && versus && \mathcal{H}_{1}: r_{0}< rk(\bold{\Pi}) \leq r_{1} \label{hipo_johansen1}
\end{align} 

Lütkepohl(2005, pp. 294)
Lütkepohl(2005, pp.340)
Tso (1981) Para regresión de rango reducido
\begin{teo}
Sea $M:=I_{T}-\Delta \bf{X}'(\Delta \bf{X}\Delta \bf{X}')^{-1}\Delta \bf{X}$, $R_{0}:=\Delta \bf{Y}M$ y $R_{1}=\bf{Y}_{-1}M$. Además 

\begin{equation}
S_{ij}:=R_{i}R'_{j}/T, \qquad i=0,1, 
\end{equation}
$\lambda_{1}\geq ... \geq \lambda_{K}$ los autovalores de $S_{11}^{-1/2}S_{10}S_{00}^{-1}S_{01}S_{11}^{-1/2}$, y $\bf{v}_{1},...,\bf{v}_{K}$, los correspondientes autovectores ortonormales 

\begin{align}
\log l  =  & -\frac{KT}{2}\log 2\pi-\frac{T}{2}\log |\bold{\Sigma}_{u}|  \nonumber \\ 
  & -\frac{1}{2}\text{tr}\left[(\Delta \bf{Y}-\boldsymbol{\alpha}\boldsymbol{\beta}'Y_{-1}-\bold{\Gamma}\Delta\bf{X})\bold{\Sigma_{u}}(\Delta \bf{Y}-\boldsymbol{\alpha}\boldsymbol{\beta}'Y_{-1}-\bold{\Gamma}\Delta\bf{X})\right] 
\end{align}
\end{teo}

Desde el resultado anterior puede plantearse el siguiente estadístico de razón de verosimilitud (LRT) para contrastar \eqref{hipo_johansen1}

\begin{align}
\lambda_{LR}(r_{0},r_{1}) & = 2[\log l(r_{1})-\log l(r_{0})] \nonumber \\ 
                          & = T\left[-\sum_{i=1}^{r_{1}}\log(1-\lambda_{i})+\sum_{i=1}^{r_{0}}\log(1-\lambda_{i})\right] \nonumber \\ 
                          & = -T\sum_{i=r_{0}+1}^{r_{1}}\log (1-\lambda_{i})
\end{align}
Cabe destacar que bajo la hipótesis nula, el estadístico no sigue una distribución estándar por lo que lo que sus valores críticos deben obtenerse mediante simulación. En particular, depende del número de relaciones de cointegracón y del tipo de hipótesis alterna a utilizar. Dos especificaciones son las más utilizadas en la literatura: 
\begin{align}
\mathcal{H}_{0}: rk(\bold{\Pi})=r_{0} &&  versus && \mathcal{H}_{1}: r_{0}<rk(\bold{\Pi})\leq K \label{hipo_johansen2}
\end{align}
y
\begin{align}
\mathcal{H}_{0}: rk(\bold{\Pi})=r_{0} &&  versus && \mathcal{H}_{1}: rk(\bold{\Pi})=r_{0}+1 \label{hipo_johansen3}
\end{align}
El estadístico $\lambda_{LR}(r_{0},K)$ para contrastar \eqref{hipo_johansen2} se denomina comunmente como el estadístico \textit{de la traza} para testear el rango de cointegración, mientras que $\lambda_{LR}(r_{0},r_{0}+1)$ es llamado estadístico de \textit{máximo autovalor}.  
}

\section{Modelo de vector de corrección del error por umbrales (TVECM)}
\subsection{Estimación del modelo TVECM}

En esta sección se reproduce lo expuesto en el artículo de Hansen \& Seo (2002). Sea $\mathbf{x}_{t}$ una serie de tiempo p-dimensional $I(1)$ la cual está cointegrada con un vector cointegrante de orden $p\times 1$. Sea $w_{t}(\beta}=\beta'x_{t}$ el término de corrección del error $I(0)$. Se puede escribir un modelo VECM linealde la siguiente forma: 

\begin{equation}
\Delta \mathbf{x}_{t} = \mathbf{A'X}_{t-1}(\boldsymbol{\beta})+\mathbf{u}_{t}
\end{equation}

\subsection{El contraste de Hansen \& Seo (2002)}

\chapter{Metodología y Datos}

\section{Fuentes de información}




\chapter{Resultados}

\newpage

\section{Imputación de valores perdidos}

<<include=FALSE>>=
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, out.width='4.5in', out.height='3.5in', fig.align='center', message=FALSE, fig.pos='H')
@


<<echo=FALSE, results='hide', message=FALSE, warning=FALSE>>=
setwd("/home/hector/GoogleDrivePersonal/Master/Tesis/GitHub/tesis_master")
source("weekly_palta.R")
#setwd("/home/hector/GoogleDrivePersonal/Master/Tesis/GitHub/tesis_master")
#source("weekly_tomate.R")
@


<<results='hide', echo=FALSE, message=FALSE>>=
if (!require(forecast)) install.packages("forecast")

fit1 = auto.arima(precio_mayorista, seasonal=FALSE)
# Filtro de Kalman 
kr1 = KalmanRun(precio_mayorista, fit1$model)
id.na1 = which(is.na(precio_mayorista))
y1 = precio_mayorista
for (i in id.na1){
  y1[i] = fit1$model$Z %*% kr1$states[i,]
}
y1[id.na1]  


fit2 = auto.arima(precio_supermercado, seasonal=FALSE)
# Filtro de Kalman 
kr2 = KalmanRun(precio_supermercado, fit2$model)
id.na2 = which(is.na(precio_supermercado))
y2 = precio_supermercado
for (i in id.na2){
  y2[i] = fit2$model$Z %*% kr2$states[i,]
}
y2[id.na2]  

@


<<fig-1,echo=F,fig.cap='Evolución de precios del palta Hass de primera calidad,2008-2016', out.width='6.5in', out.height='3.5in', fig.align='center', fig.pos='H'>>=

par(family="serif", bty="l", bg="white", cex.lab=1) # opciones gráficas
ts.plot(exp(precio_mayorista), exp(precio_supermercado), lty=1:2,
        lwd=1, ylab="$/kilo", xlab="Tiempo")
legend("topleft", legend = c("Mayorista", "Supermercado"),lty=1:2, lwd=2, cex=0.8)

@



<<fig-2,echo=F,fig.cap='Imputación de valores perdidos a través del filtro de Kalman', out.width='6.5in', out.height='4.5in', fig.align='center', fig.pos='H'>>=
layout(matrix(c(1,1,1,1,1,
                2,2,2,2,2),2,5, byrow=TRUE))

par(family="serif", bty="l", par(family="serif", bty="l")) # opciones gráficas
plot(precio_mayorista, lty=2 ,ylab="Precio palta mayorista ($/kilo)", 
     xlab="Tiempo")
lines(y1, lwd=1, lty=1)
points(time(y1)[id.na1], y1[id.na1], col = "red", pch = 18, cex=2)
legend("topleft", legend = c("Valores imputados"), 
  col = c("red"), pch = c(18), cex=1.5)

plot(precio_supermercado, lty=2 ,ylab="Precio palta supermercado ($/kilo)", 
     xlab="Tiempo")
lines(y2, lwd=1, lty=1)
points(time(y2)[id.na2], y2[id.na2], col = "blue", pch = 18, cex=2)
legend("topleft", legend = c("Valores imputados"), 
  col = c("blue"), pch = c(18), cex=1.5)

@

\section{Análisis del orden de integración de las series}
\subsection{Análisis gráfico}

Para analizar el orden de integración de las series es de utilidad usar herramientas gráficas que entreguen cierta orientación sobre el comportamiento de las series antes de realizar un análisis formal a través de contrastes de hipótesis. 

Cabe señalar que, como un intento de estabilizar la varianza de las series, estas serán trabajadas en logaritmo.

\subsubsection{Análisis de las series en nivel}

En el caso del logaritmo de los precios mayoristas de la palta, puede apreciarse una media no constante, aunque lo mismo no es directamente apreciable  para la varianza. Por otro lado, su correlograma muestra autocorrelaciones significativas más allá de 52 períodos de rezago, lo que permite afirmar que el proceso tendría una memoria prolongada y que por tanto, no es estacionario (Véase figura \ref{fig5.1}).

Para el caso de la serie del logaritmo del precio de la palta en supermercados, se puede observar un comportamiento bastante similar. Es decir, una media que no es constante debido a una tendencia, cuya naturaleza se determina más adelante; y una memoria prolongada al observar el correlograma correspondiente (Véase figura \ref{fig5.2}).  


<<fig-2.1,echo=F,fig.cap='Evolución del logaritmo del precio mayorista de la palta, 2008-2016\\label{fig5.1}', out.width='4.5in', out.height='3.5in', fig.align='center'>>=
par(family="serif", bty="l")
layout(matrix(c(1,1,1,1,1,
                2,2,0,3,3),ncol = 5, byrow=TRUE))
plot(y1, main="a) Evolución log(precios) mayoristas, 2008-2016", 
     ylab="$/kilo")
Acf(y1, main="b) Función de autocorrelación", lag.max = 52)
Pacf(y1, main="c) Función de autocorrelación parcial", lag.max = 52)
@


<<fig-2.2,echo=F,fig.cap='Evolución del logaritmo del precio en supermercado de la palta, 2008-2016\\label{fig5.2}', out.width='4.5in', out.height='3.5in', fig.align='center'>>=
par(family="serif", bty="l")
layout(matrix(c(1,1,1,1,1,
                2,2,0,3,3),ncol =5, byrow=TRUE))
plot(y2, main="a) Evolución log(precios) supermercado, 2008-2016", 
     ylab="$/kilo")
Acf(y2, main="b) Función de autocorrelación", lag.max = 52)
Pacf(y2, main="c) Función de autocorrelación parcial", lag.max = 52)
@

\subsubsection{Análisis de las series en diferencias}

A continuación se procedió a diferenciar las series, pues existe la sospecha de la presencia de raíz unitaria en ambas, cuestión que será determinada más adelante.

Al analizar las figuras \ref{fig5.3} y \ref{fig5.4} se observan algunos rezagos significativos en el correlograma, lo que puede servir de orientación para determinar el orden de integración de las series. A pesar de lo anterior, se observa de todas maneras que el comportamiento de la varianza no es estable a lo largo del tiempo en ambos casos.  


<<fig-2.3,echo=F,fig.cap='Evolución del logaritmo del precio mayorista de la palta, 2008-2016\\label{fig5.3}', out.width='4.5in', out.height='3.5in', fig.align='center'>>=
par(family="serif", bty="l")
layout(matrix(c(1,1,1,1,1,
                2,2,0,3,3),ncol = 5, byrow=TRUE))
plot(diff(y1), main="a) Evolución log(precios) mayoristas, 2008-2016", 
     ylab="$/kilo")
Acf(diff(y1), main="b) Función de autocorrelación", lag.max = 52)
Pacf(diff(y1), main="c) Función de autocorrelación parcial", lag.max = 52)
@


<<fig-2.4,echo=F,fig.cap='Evolución del logaritmo del precio en supermercado de la palta, 2008-2016\\label{fig5.2}', out.width='4.5in', out.height='3.5in', fig.align='center'>>=
par(family="serif", bty="l")
layout(matrix(c(1,1,1,1,1,
                2,2,0,3,3),ncol =5, byrow=TRUE))
plot(diff(y2), main="a) Evolución log(precios) supermercado, 2008-2016", 
     ylab="$/kilo")
Acf(diff(y2), main="b) Función de autocorrelación", lag.max = 52)
Pacf(diff(y2), main="c) Función de autocorrelación parcial", lag.max = 52)
@



\subsection{Contrastes de raíz unitaria}

\subsubsection{Análisis de las series originales}
Para determinar de manera formal la presencia de raíces unitarias en las series analizadas se procede a continuación a aplicar una serie de contrastes comúnmente utilizados en la literatura. 


<<echo=FALSE, include=FALSE>>=
if (!require(urca)) install.packages("urca")

dickey11 = ur.df(y1, type="drift", selectlags = c("BIC"))
dickey21 = ur.df(y2, type="drift", selectlags = c("BIC"))
summary(dickey11)
summary(dickey21)

@

A continuación se aplicará el contraste de Dickey-Fuller aumentado bajo el supuesto de que el proceso subyacente tiene drift y tendencia y bajo el supuesto de que sólo tiene drift. 

\begin{center}
\begin{table}[h]
\caption{Contraste de Dickey-Fuller aumentado (con drift)\label{tab:dickey1}}
\centering
\begin{threeparttable}
\begin{tabular}{@{}llllll@{}}
\toprule \\
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estimaciones} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
$\tau_{2} $  & -2.5725 &  -1.6393  & -2.57 & -2.87 & -3.44 \\
$\phi_{1} $  & 3.4095  &  1.6354   & 3.79 & 4.61 &  6.47\\
\bottomrule \\
\end{tabular}
\begin{tablenotes}
\small 
\item $^{a}$: Con un rezago, de acuerdo a criterio BIC. 
\item $^{b}$: Con un rezago, de acuerdo a criterio BIC. 
\end{tablenotes}
\end{threeparttable}
\end{table}
\end{center}

<<echo=FALSE, include=FALSE>>=
dickey1 = ur.df(y1, type="trend", selectlags = c("BIC"))
dickey2 = ur.df(y2, type="trend", selectlags = c("BIC"))
summary(dickey1)
summary(dickey2)

@

El cuadro \ref{tab:dickey1} muestra que la evidencia estadística provista por la realización de la serie es apenas suficiente para rechazar la hipótesis $\mathcal{H}_{0}: \rho = 1$ a un nivel de significancia de 10 \%. Por otro lado, la hipótesis $\mathcal{H}_{0}: (\alpha,\rho) = (0,1) $ no puede ser rechazada.

Con respecto a la serie de precios de supermercados la evidencia va en la misma dirección. 

De acuerdo a lo anterior, la serie no contendría una raíz unitaria. De todas maneras, es necesario formular otras representaciones del proceso, como bien podría ser incluir una tendencia determinista (a continuación) o utilizar otros contrastes. 

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste de Dickey-Fuller aumentado (con tendencia)\label{tab:dickey2}}
\begin{tabular}{@{}llllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estimaciones} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
$\tau_{3} $  & -3.4073 &  -2.1143  &  -3.13 & -3.42  &  -3.98 \\
$\phi_{2} $  & 3.9655  &  1.6848   &  4.05 &  4.71 &  6.15 \\
$\phi_{3} $  & 5.8467  &  2.2351   &  5.36 &  6.30 &  8.34 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small 
\item $^{a}$: Con un rezago, de acuerdo a criterio BIC. 
\item $^{b}$: Con un rezago, de acuerdo a criterio BIC. 
\end{tablenotes}
\end{threeparttable}
\end{table}


El cuadro \ref{tab:dickey2} muestra que para el caso de la serie de precios mayoristas, la hipótesis $\mathcal{H}_{0}: \rho=1$ se rechaza a un nivel de significancia de $10\%$. Mientras que la hipótesis $\mathcal{H}_{0}: (\alpha, \beta, \rho)=(0,0,1)$  no muestra evidencia estadística suficiente para ser rechaza a los niveles de significancia propuestos. Por último, la hipótesis $\mathcal{H}_{0}: (\alpha, \beta,\rho)=(\alpha,0,1)$ puede ser rechazada sólo a un 10\% de significancia. 

Para el caso de la serie de precios de supermercado, la hipótesis $\mathcal{H}_{0}: \rho=1$ no puede ser rechazada a ninguno de los niveles de significancia propuestos. Mientras que el contraste tampoco provee información suficiente para rechazar $\mathcal{H}_{0}: (\alpha, \beta, \rho)=(0,0,1)$. Por último, la hipótesis $\mathcal{H}_{0}: (\alpha, \beta,\rho)=(\alpha,0,1)$ puede ser rechaza sólo a un 10\% de significancia. 

El resultado de este contraste es más bien contradictorio, pues no permite concluir que ambas series contengan una raíz unitaria, bajo los diferentes escenarios que sus hipótesis configuran. Queda la posibilidad entonces de que las series tengan un comportamiento estacionario en tendencia, situación que será abordada con el contraste KPSS. 

Los resultados del cuadro \ref{fig5.3}  muestran que para ambas series se rechaza la hipótesis de estacionariedad de la serie a nivel de significancia del 1\%. Razón por la cual se descarta la hipótesis de estacionariedad en tendencia. 

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste KPSS (con tendencia determinista) \label{fig5.3}}
\begin{tabular}{@{}lrllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estadístico} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{$\mathcal{H}_0$} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
$\tau_{3} $  & 0.2405 &  0.3223 & 0.119 & 0.146 & 0.216 \\
\bottomrule
\end{tabular}
\label{tab-6}
\begin{tablenotes}
\small 
\item $^{a}$: Con cinco rezagos de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\item $^{b}$: Con cinco rezagos de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\end{tablenotes}
\end{threeparttable}
\end{table}

Por otro lado, los resultados del cuadro \ref{fig5.4} indican que la hipótesis de estacionariedad en niveles se rechaza fuertemente en ambos casos. 

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste KPSS (sin tendencia determinista) \label{fig5.4}}
\begin{tabular}{@{}lrllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estadístico} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{$\mathcal{H}_0$} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
$\tau_{3} $  & 3.5537 &  3.8913 & 0.347 & 0.463 & 0.739 \\
\bottomrule
\end{tabular}
\label{tab-7}
\begin{tablenotes}
\small 
\item $^{a}$: Con cinco rezagos de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\item $^{b}$: Con cinco rezagos de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\end{tablenotes}
\end{threeparttable}
\end{table}

El contraste de Phillips Perron indica que no se puede rechazar la hipótesis de raíz unitaria para ambas series. 

<<include=FALSE>>=
pperron1 =ur.pp(y1, type=c("Z-alpha"), model = c("trend"), lags = c("short")) 

pperron2 =ur.pp(y2, type=c("Z-alpha"), model = c("trend"), lags = c("short")) 

@

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste Phillips \& Perron$^{a}$ (con tendencia determinista)\label{tab:pperron1}}
\begin{tabular}{@{}llllll@{}}
\toprule
\multicolumn{1}{c}{} &
\multicolumn{1}{l}{Mayorista} &
\multicolumn{1}{l}{Supermercado} & 
90\% & 95\% & 99\% 
\\
\cmidrule(l){2-2} \cmidrule(l){3-3} \cmidrule(l){4-6} \\
$Z(t_{\hat{\alpha}})$ &-22.1367 & -11.958 & -3.13 & -3.42 & -3.98 \\ 
$Z(t_{\hat{\mu}})$    &  1.5224 & 1.0702  &  4.04 & 4.71  & 6.15  \\ 
$Z(t_{\hat{\beta}})$  &  2.2482 & 1.6792  &  5.63 & 6.30  & 8.34 \\
\bottomrule
\end{tabular}
\label{tab-4}
\begin{tablenotes}
\small 
\item $^{a}$: Con cinco rezagos de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\end{tablenotes}
\end{threeparttable}
\end{table}

El cuadro \ref{tab:pperron1} muestra que el contraste rechaza la hipótesis de raíz unitaria, aunque no permite identificar con claridad la estructura de los términos deterministas. 


<<include=FALSE>>=
pperron11 =ur.pp(y1, type=c("Z-alpha"), model = c("constant"), lags = c("short")) 

pperron21 =ur.pp(y2, type=c("Z-alpha"), model = c("constant"), lags = c("short")) 

@


\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste Phillips \& Perron$^{a}$ (con tendencia determinista) \label{tab:pperron2}}
\begin{tabular}{@{}llllll@{}}
\toprule
\multicolumn{1}{c}{} &
\multicolumn{1}{l}{Mayorista} & 
\multicolumn{1}{l}{Supermercado} & 
90\% & 95\% & 99\% \\ 
\\
\cmidrule(l){2-2} \cmidrule(l){3-3} \cmidrule(l){4-6} \\
$Z(t_{\hat{\alpha}})$ & -13.3185 & -6.8276 &  -2.57 & -2.87 & -3.44 \\
$Z(t_{\hat{\mu}})$ & 2.5034 & 1.8389 & 3.79 & 4.61 & 6.47 \\
\bottomrule
\end{tabular}
\label{tab-5}
\begin{tablenotes}
\small 
\item $^{a}$: Con cinco rezagos de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\end{tablenotes}
\end{threeparttable}
\end{table}

Al observar el cuadro \ref{tab:pperron2} queda de manifiesto el rechazo de la hipótesis de raíz unitaria, aunque por cierto, no se puede afirmar con exactitud el comportamiento de los términos deterministas. 

<<include=FALSE>>=

ers1 = ur.ers(y1, type = c("P-test"), model="trend", lag.max = 52)

ers2 = ur.ers(y2, type = c("P-test"), model="trend", lag.max = 52)

ers11 = ur.ers(y1, type = c("P-test"), model="constant", lag.max = 52)

ers21 = ur.ers(y2, type = c("P-test"), model="constant", lag.max = 52)
@

Hecho lo anterior, se procede a aplicar el contraste ERS, utilizando en primer lugar un modelo con constante y tendencia deteminista. El cuadro \ref{fig5.5} muestra que para el caso de los mayoristas no se puede rechazar la hipótesis nula de raíz unitaria para ninguno de los niveles de significancia prescritos, mientras que para el caso de la serie supermercado dicha hipótesis se rechaza al menos al 5\%.  

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste de Elliot, Rothenberg \& Stock (con tendencia determinista)\label{fig5.5}}
\begin{tabular}{@{}lrllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estadístico} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
  & 3.8715 &  10.0306 & 6.89 & 5.62 & 3.96 \\
\bottomrule
\end{tabular}
\label{tab-8}
\begin{tablenotes}
\small 
\item $^{a}$: Con un rezago, de acuerdo a criterio BIC. 
\item $^{b}$: Con un rezago, de acuerdo a criterio BIC. 
\end{tablenotes}
\end{threeparttable}
\end{table}

El cuadro \ref{fig5.6}

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste de Elliot, Rothenberg \& Stock (con constante)\label{fig5.6}}
\begin{tabular}{@{}lrllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estadístico} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
  & 3.0049 &  12.0408 & 4.48 & 3.26 & 1.99 \\
\bottomrule
\end{tabular}
\label{tab-9}
\begin{tablenotes}
\small 
\item $^{a}$: Con un rezago, de acuerdo a criterio BIC. 
\item $^{b}$: Con un rezago, de acuerdo a criterio BIC. 
\end{tablenotes}
\end{threeparttable}
\end{table}


<<include=FALSE>>=
ers_1 = ur.ers(y1, type = c("DF-GLS"), model="trend", lag.max = 5)

ers_2 = ur.ers(y2, type = c("DF-GLS"), model="trend", lag.max = 5)

ers_11 = ur.ers(y1, type = c("DF-GLS"), model="constant", lag.max = 5)

ers_21 = ur.ers(y2, type = c("DF-GLS"), model="constant", lag.max = 5)

@


<<include=FALSE>>=
kpss1 = ur.kpss(y1, type=c("tau"), lags=c("short"))

kpss2 = ur.kpss(y2, type=c("tau"), lags=c("short"))

kpss11 = ur.kpss(y1, type=c("mu"), lags=c("short"))

kpss21 = ur.kpss(y2, type=c("mu"), lags=c("short"))
@


\subsubsection{Análisis de las series en diferencias}

Una vez establecida la presencia de raíces unitarias en las series, se procederá a aplicar los contrastes nuevamente para las series en diferencias

<<echo=FALSE, include=FALSE>>=
if (!require(urca)) install.packages("urca")

dickey11 = ur.df(diff(y1), type="none", selectlags = c("BIC"))
dickey21 = ur.df(diff(y2), type="none", selectlags = c("BIC"))
summary(dickey11)
summary(dickey21)

@


\begin{center}
\begin{table}[h]
\caption{Contraste de Dickey-Fuller aumentado (sin drift y tendencia)\label{tab:dickey1}}
\centering
\begin{threeparttable}
\begin{tabular}{@{}llllll@{}}
\toprule \\
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estimaciones} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
$\tau_{3} $  &  -14.0093 &  -14.3253  & -1.62 & -1.95 & -2.58 \\
\bottomrule \\
\end{tabular}
\begin{tablenotes}
\small 
\item $^{a}$: Con un rezago, de acuerdo a criterio BIC. 
\item $^{b}$: Con un rezago, de acuerdo a criterio BIC. 
\end{tablenotes}
\end{threeparttable}
\end{table}
\end{center}



Por otro lado, los resultados del cuadro \ref{fig5.4} indican que la hipótesis de estacionariedad en niveles se rechaza fuertemente en ambos casos. 

<<include=FALSE>>=
kpss1 = ur.kpss(diff(y1), type=c("mu"), lags=c("short"))
summary(kpss1)
kpss2 = ur.kpss(diff(y2), type=c("mu"), lags=c("short"))
summary(kpss2)
@

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste KPSS (sin tendencia determinista) \label{fig5.4}}
\begin{tabular}{@{}lrllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estadístico} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{$\mathcal{H}_0$} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
$\tau_{3} $  & 0.0236 &  0.0433 & 0.347 & 0.463 & 0.739 \\
\bottomrule
\end{tabular}
\label{tab-7}
\begin{tablenotes}
\small 
\item $^{a}$: Con cinco rezagos de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\item $^{b}$: Con cinco rezagos de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\end{tablenotes}
\end{threeparttable}
\end{table}

El contraste KPSS muestra claramente como, ahora que la serie ha sido diferenciada, no se puede rechazar la hipótesis nula de estacionariedad. 

El contraste de Phillips Perron indica que no se puede rechazar la hipótesis de raíz unitaria para ambas series. 

<<include=FALSE>>=
pperron1 =ur.pp(diff(y1), type=c("Z-alpha"), model = c("constant"), lags = c("short")) 
summary(pperron1)
pperron2 =ur.pp(diff(y2), type=c("Z-alpha"), model = c("constant"), lags = c("short")) 
summary(pperron2)
@

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste Phillips \& Perron$^{a}$ (con tendencia determinista)\label{tab:pperron1}}
\begin{tabular}{@{}llllll@{}}
\toprule
\multicolumn{1}{c}{} &
\multicolumn{1}{l}{Mayorista} &
\multicolumn{1}{l}{Supermercado} & 
90\% & 95\% & 99\% 
\\
\cmidrule(l){2-2} \cmidrule(l){3-3} \cmidrule(l){4-6} \\
$Z(t_{\hat{\alpha}})$ &-411.6423 & -571.565 & -3.13 & -3.42 & -3.98 \\ 
$Z(t_{\hat{\mu}})$    &  0.3197 & 0.7824  &  4.04 & 4.71  & 6.15  \\ 
\bottomrule
\end{tabular}
\label{tab-4}
\begin{tablenotes}
\small 
\item $^{a}$: Con un rezago de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\end{tablenotes}
\end{threeparttable}
\end{table}

El cuadro \ref{tab:pperron1} muestra que el contraste rechaza la hipótesis de raíz unitaria, y que como es de esperar, la serie no contiene término constante. 


<<include=FALSE>>=
pperron11 =ur.pp(y1, type=c("Z-alpha"), model = c("constant"), lags = c("short")) 

pperron21 =ur.pp(y2, type=c("Z-alpha"), model = c("constant"), lags = c("short")) 

@


\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste Phillips \& Perron$^{a}$ (con tendencia determinista) \label{tab:pperron2}}
\begin{tabular}{@{}llllll@{}}
\toprule
\multicolumn{1}{c}{} &
\multicolumn{1}{l}{Mayorista} & 
\multicolumn{1}{l}{Supermercado} & 
90\% & 95\% & 99\% \\ 
\\
\cmidrule(l){2-2} \cmidrule(l){3-3} \cmidrule(l){4-6} \\
$Z(t_{\hat{\alpha}})$ & -13.3185 & -6.8276 &  -2.57 & -2.87 & -3.44 \\
$Z(t_{\hat{\mu}})$ & 2.5034 & 1.8389 & 3.79 & 4.61 & 6.47 \\
\bottomrule
\end{tabular}
\label{tab-5}
\begin{tablenotes}
\small 
\item $^{a}$: Con cinco rezagos de acuerdo a la siguiente regla $\root 4 \of {4 \times (n/100)}$. 
\end{tablenotes}
\end{threeparttable}
\end{table}

Al observar el cuadro \ref{tab:pperron2} queda de manifiesto el rechazo de la hipótesis de raíz unitaria, aunque por cierto, no se puede afirmar con exactitud el comportamiento de los términos deterministas. 

<<include=FALSE>>=

ers1 = ur.ers(y1, type = c("P-test"), model="trend", lag.max = 52)

ers2 = ur.ers(y2, type = c("P-test"), model="trend", lag.max = 52)

ers11 = ur.ers(y1, type = c("P-test"), model="constant", lag.max = 52)

ers21 = ur.ers(y2, type = c("P-test"), model="constant", lag.max = 52)
@

Hecho lo anterior, se procede a aplicar el contraste ERS, utilizando en primer lugar un modelo con constante y tendencia deteminista. El cuadro \ref{fig5.5} muestra que para el caso de los mayoristas no se puede rechazar la hipótesis nula de raíz unitaria para ninguno de los niveles de significancia prescritos, mientras que para el caso de la serie supermercado dicha hipótesis se rechaza al menos al 5\%.  

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste de Elliot, Rothenberg \& Stock (con tendencia determinista)\label{fig5.5}}
\begin{tabular}{@{}lrllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estadístico} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
  & 3.8715 &  10.0306 & 6.89 & 5.62 & 3.96 \\
\bottomrule
\end{tabular}
\label{tab-8}
\begin{tablenotes}
\small 
\item $^{a}$: Con un rezago, de acuerdo a criterio BIC. 
\item $^{b}$: Con un rezago, de acuerdo a criterio BIC. 
\end{tablenotes}
\end{threeparttable}
\end{table}

El cuadro \ref{fig5.6}

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste de Elliot, Rothenberg \& Stock (con constante)\label{fig5.6}}
\begin{tabular}{@{}lrllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estadístico} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Mayorista$^{a}$} &
 \multicolumn{1}{c}{Supermercado$^{b}$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
  & 3.0049 &  12.0408 & 4.48 & 3.26 & 1.99 \\
\bottomrule
\end{tabular}
\label{tab-9}
\begin{tablenotes}
\small 
\item $^{a}$: Con un rezago, de acuerdo a criterio BIC. 
\item $^{b}$: Con un rezago, de acuerdo a criterio BIC. 
\end{tablenotes}
\end{threeparttable}
\end{table}


<<include=FALSE>>=
ers_1 = ur.ers(y1, type = c("DF-GLS"), model="trend", lag.max = 5)

ers_2 = ur.ers(y2, type = c("DF-GLS"), model="trend", lag.max = 5)

ers_11 = ur.ers(y1, type = c("DF-GLS"), model="constant", lag.max = 5)

ers_21 = ur.ers(y2, type = c("DF-GLS"), model="constant", lag.max = 5)

@

A partir del análisis recién expuesto, se puede concluir que ambas series al ser diferenciadas tienen un comportamiento estacionario. De forma tal que ambas series son I(1).

De esta forma, se procederá a determinar si la tendencia estocástica es compartida a través de un análisis de cointegración. 

\section{Determinación del rango de cointegración y estimación del modelo del modelo lineal de corrección del error}

En este apartado se trabajó principalmente con el paquete \texttt{vars} (Pfaff, 2008). 

<<echo=FALSE>>=
if (!require(vars)) install.packages("vars"); require(vars)
if (!require(tsDyn)) install.packages("tsDyn"); require(vars)
if (!require(ggplot2)) installed.packages("ggplot2")
if (!require("reshape2")) install.packages("reshape2")
if (!require(RColorBrewer)) install.packages("RColorBrewer")

datos = data.frame(y1,y2)
names(datos) = c("mayorista", "supermercado")
@

Antes de la determinación del rango de cointegración del proceso, es necesario tener en cuenta que el uso del contraste de cointegración de Johansen que se utilizará para dichos fines es sensible a la especificación del modelo vectorial de corrección del equilibrio que subyace. Para la especificación de dicho modelo se recurrió a diferentes criterios. 

De manera similar a como señalan Ben Kaabia \& Gil (2008), se observa que al realizar los contrastes univariantes de raíz unitaria, no se rechaza la existencia de una raíz unitaria en torno a una constante no nula. Así también, al realizar los mismos contrastes para las series en primeras diferencias, las series resultaron estacionarias. Por último, en términos económicos, la presencia de una constante indica que existe una diferencia de escala entre los precios mayoristas y detallistas. 

El número de rezagos a incluir en el modelo se determinó con el objetivo de prevenir problemas de autocorrelación. De esta manera, se estimó el modelo secuencialmente utilizando entre 2 y  12 rezagos y se calculó el estadístico de Ljung-Box multivariado para los residuos rezagados entre el orden mínimo posible y aquellos de orden 52. Los p-valores correspondientes a cada uno de los contrastes están resumidos en la figura \ref{fig5.6}. De esta manera, se aprecia que la hipótesis nula de independencia no se puede rechazar a un nivel de significancia de 5\% en la mayoría de los casos para el modelo con ocho términos rezagados. 

<<out.width='5in', out.height='3.5in',fig.cap="Número de Rezagos para el contraste de Independencia\\label{fig5.6}">>==
#Para ver las fechas 
fechas = data.frame(as.yearmon(time(datos[,1])))

vecm2 = lapply(2:8, function(x) ca.jo(datos, type=c("trace"), ecdet=c( "const"), K=x, spec="transitory", season=NULL))

modelo = lapply(1:7, function(x) vec2var(vecm2[[x]], r=1))

lags = 3:52
resultado = sapply(lags, function(x) lapply(1:length(modelo), 
                        function(y) serial.test( modelo[[y]],
                       lags.pt = x)$serial$p.value) %>% as.numeric()) %>% t() %>% 
  data.frame() %>% mutate(rezago = lags)

meltresultado = melt(resultado, id = "rezago", na.rm=TRUE) %>% 
  rename(Modelo = variable, `p-value`=value) 

meltresultado$Modelo = recode(meltresultado$Modelo,
                              'X1'='2 rezagos',
                              'X2'='3 rezagos',
                              'X3'='4 rezagos',
                              'X4'='5 rezagos',
                              'X5'='6 rezagos',
                              'X6' = '7 rezagos',
                              'X7' = '8 rezagos')

ggplot(meltresultado, aes(x=rezago, y=`p-value`, colour=Modelo, group=Modelo)) + 
  geom_line(size=1.2)+geom_hline(yintercept = 0.05, color="red")+
  geom_hline(yintercept = 0.1, col="red2")+
  theme(panel.background = element_rect(),
        plot.background = element_rect(colour = "white",size = 0.5), 
        axis.text.x = element_text(size=10, family="serif"), 
        axis.title.x = element_text(size=15, family="serif"), 
        axis.title.y = element_text(size=15, family = "serif"), 
        legend.background = element_rect(fill="grey95"), 
        legend.text = element_text(size=10, family="serif"), 
        legend.title = element_text(face="bold", family="serif"), 
        legend.title.align = 0.5)+
#  scale_colour_manual(values = brewer.pal(12,"Blues"))+
  scale_x_continuous(breaks = c(5,10,15,20,25,30,35,40,45,50))+
  scale_y_continuous(breaks = seq(0.0,1,0.05))
@

De esta forma, el modelo definitivo a estimar resultó ser el siguiente: 

\begin{equation}
\Delta \mathbf{y}_{t} = \boldsymbol{\Pi}\mathbf{y}_{t-1}+\sum_{i=1}^{8}\boldsymbol{\Gamma_{i}}\mathbf{y}_{t-i}+\boldsymbol{\varepsilon}_{t}
\end{equation}

Entonces, definido el número de rezagos a utilizar y la estructura del vector cointegrante, se procedió a aplicar el contraste de cointegración de Johansen, cuyos resultados pueden apreciarse en los cuadros \ref{tab5.15} y \ref{tab5.16}


<<include = FALSE, echo=FALSE >>=
## Pruebo dos formulaciones equivalentes 
modelo_alternativo = VECM(datos, lag=8, r=1, LRinclude= c("const"), 
              estim = c("ML"))

modelo_ = ca.jo(datos, type = c("trace"), ecdet = c("const"), K=9,
               spec = c("longrun"))

modelo1_ = ca.jo(datos, type = c("eigen"), ecdet = c("const"), K=9,
               spec = c("longrun"))


@



\begin{table}[h]
\caption{Contraste de la \textit{la traza} de cointegración de Johansen\label{tab5.15}}
\begin{center}
\begin{tabular}{@{}lrllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estadístico} &
\multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{$\mathcal{H}_0$} & \multicolumn{2}{c}{$p = 8$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
$r \leq 1$  & \multicolumn{2}{c}{5.82}  & 7.52 & 9.24 & 12.97\\
$r = 0$     & \multicolumn{2}{c}{ 36.63}  & 17.85 & 19.96 & 24.60\\
\bottomrule
\end{tabular}
\end{center}
\label{tab-10}
\end{table}

En el cuadro \ref{tab5.15} se observa el rechazo de la hipótesis $\mathcal{H}_{0}: = 0$ lo que descarta que la especificación adecuada sea un modelo VAR en niveles. Por otro lado, la hipótesis nula $\mathcal{H}_{0}\leq 1$ no puede rechazarse. 


\begin{table}[h]
\caption{Contraste del \textit{máximo autovalor} de cointegración de Johansen\label{tab5.16}}
\begin{center}
\begin{tabular}{@{}lrllll@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Estadístico} & \multicolumn{3}{c}{Valores críticos} \\
\cmidrule(l){2-3} \cmidrule(l){4-6} \\
\multicolumn{1}{l}{$\mathcal{H}_0$} & \multicolumn{2}{c}{$p = 8$} &
\multicolumn{1}{l}{90\%}&
\multicolumn{1}{l}{95\%}&
\multicolumn{1}{l}{99\%}
\\
\midrule
$r \leq 1$ & \multicolumn{2}{c}{5.82} & 7.52 & 9.24 & 12.97 \\
$r = 0$ & \multicolumn{2}{c}{30.82} & 13.75 & 15.67 & 20.20 \\
\bottomrule
\end{tabular}
\end{center}
\label{tab-11}
\end{table}

Al realizar la prueba de acuerdo al máximo autovalor, se observa el mismo resultado. 

De esta manera, el modelo puede especificarse como 

\begin{equation}
 \Delta\mathbf{y}_{t} = \boldsymbol{\alpha \beta}^{'}\left[\begin{array}{c}1 \\ \mathbf{y}_{t-1}\end{array}\right]+\sum_{i=1}^{8}\boldsymbol{\Gamma}_{i}\Delta\mathbf{y}_{t-i}+\boldsymbol{\varepsilon}_{t}
\end{equation}

Donde $\boldsymbol{\alpha}=\left[\begin{array}{c} \alpha_{1} \\ \alpha_{2} \\ \alpha_{3} \end{array}\right]$ y $\boldsymbol{\beta}^{'} = \left[\begin{array}{ccc} \beta_{1} & \beta_{2} & \beta_{3} \end{array}\right]$


<<>>=
not_restrict = VECM(datos, lag=8, estim="ML", r=1, LRinclude = c("const"))

beta = matrix(c(1,-1), ncol =1)
restrict = VECM(datos, lag = 8, estim = "ML", r = 1, beta = beta)

D = 2*(logLik(not_restrict)-logLik(restrict))

pchisq(D, df = restrict$npar-not_restrict$npar)
@



\begin{table}[h]
\centering
\begin{threeparttable}
\caption{Contraste de Elliot, Rothenberg \& Stock (con constante)\label{fig5.6}}
\begin{tabular}{@{}lll@{}}
\toprule
 & $\Delta \text{mayorista}_{t} $ & $\Delta \text{supermerado}_{t}$ \\ 
 \midrule 
 $\text{corrección del error}$ & -0.146592   &  0.027821 \\     
$\Delta$mayorista$_{t-1}$   &   0.065270 &   0.095569  \\   
$\Delta$supermercado$_{t-1}$  & 0.333719  &  -0.095055 \\     
$\Delta$mayorista$_{t-2}$  & -0.075599  &   0.112612  \\   
$\Delta$supermercado$_{t-1}$  & 0.296286  &  -0.042207 \\     
$\Delta$mayorista$_{t-3}$ &  -0.095907  & 0.063245     \\
$\Delta$supermercado$_{t-3}$  & 0.198395  &   0.006723  \\   
$\Delta$mayorista$_{t-4}$   &  -0.174854  &   0.046165 \\     
$\Delta$supermercado$_{t-4}$  & 0.212239  &   0.053372  \\   
$\Delta$mayorista$_{t-5}$   &  -0.175601  &  -0.004331 \\     
$\Delta$supermercado$_{t-5}$  & 0.167277  &  -0.057114  \\   
$\Delta$mayorista$_{t-6}$   & -0.064872   &  0.068671 \\     
$\Delta$supermercado$_{t-1}$  & 0.148495  &  -0.011887 \\     
$\Delta$mayorista$_{t-7}$   &  -0.122949  &   0.101965 \\     
$\Delta$supermercado$_{t-7}$  & 0.332634  &  -0.042574  \\   
$\Delta$mayorista$_{t-8}$   &  -0.067370  &   0.009668  \\   
$\Delta$supermercado$_{t-1}$  & 0.107484  &  -0.033937  \\ 
\bottomrule
\end{tabular}
\label{tab-9}
\begin{tablenotes}
\small 
\item $^{a}$: Con un rezago, de acuerdo a criterio BIC. 
\item $^{b}$: Con un rezago, de acuerdo a criterio BIC. 
\end{tablenotes}
\end{threeparttable}
\end{table}


<<echo = F>>=
#source("girf_sample.R")

modelo__ = cajorls(modelo_, r=1)

var_version = vec2var(modelo_, r= 1)

impulso = irf(var_version, n.ahead = 52)
impulso2 = irf(var_version, n.ahead = 52, ortho = FALSE)
@



<<graph5.6, echo=FALSE, fig.cap='Función ortogonal de impulso respuesta\\label{graph5.6}'>>=
plot(impulso)
@

<<graph5.7, echo=FALSE, fig.cap='Función acumulada de impulso respuesta\\label{graph5.6}'>>=

plot(impulso2)
@


\section{Diagnósticos del modelo lineal}

<<graph5.8, echo=FALSE, fig.cap='Residuos del modelo\\label{graph5.8}'>>=
layout(matrix(c(1,1,1,1,1,
                2,2,2,2,2,
                3,3,0,4,4),3,5, byrow=TRUE))
plot(ts(residuals(var_version)[,1]), main = "Residuos de la ecuación mayorista")
plot(ts(residuals(var_version)[,1]), main = "Residuos de la ecuación supermercado")
Acf(residuals(var_version)[,1], main = "ACF mayorista")
Acf(residuals(var_version)[,2], main = "ACF supermercado")
@

<<echo=FALSE>>=
res = residuals(var_version)
if (!require(plot3D)) install.packages("plot3D")

x = res[,1]
y = res[,2]

x_c = cut(x,20)
y_c = cut(y,20)

z = table(x_c,y_c)

layout(matrix(c(1,1,1,1,1,
                2,2,2,2,2),2,5, byrow=TRUE))

@


<<fig-5.3.1,echo=F,fig.cap='Histograma bivariado de los residuos del modelo', out.width='3.5in', out.height='3.5in', fig.align='center', message=FALSE, fig.pos='H'>>=
hist3D(z=z, border="black", contour=TRUE)

@

<<fig-5.3.2,echo=F,fig.cap='Mapa de calor de los residuos del modelo', out.width='3.5in', out.height='3.5in', fig.align='center', message=FALSE, fig.pos='H'>>=
image2D(z=z, border="black")
@


<<include = FALSE, echo = FALSE>>=

if (!require(asbio)) install.packages("asbio")

errores = data.frame(residuals(var_version))
DH.test(errores, names(errores))
normality.test(var_version)
arch.test(var_version, lags.multi = 9)
@

\begin{table}[h]
\centering
\caption{Diagnósticos del modelo}
\begin{tabular}{@{}llll@{}}
\toprule \\ 
Contraste   & $E$ & df & $\mathbb{P}(\chi^{2}>E)$ \\
\midrule \\ 
Doornik \& Hansen & 246.913 & 4 & 2.11$\times 10^{-45}$ \\
Jarque-Bera (Multivariado) & 30.141 & 4 & $<$2.85$\times 10^{-7}$ \\
ARCH (Multivariado) & 144.4 & 81 & 1.89$\times 10^{-5}$ \\ 
\bottomrule 
\end{tabular}
\end{table}

\section{Determinación del rango de cointegración y estimación del modelo del modelo lineal de corrección del error}


<<fig-5.9,echo=F,fig.cap='Modelo de corrección del error por umbrales', out.width='4.5in', out.height='4.5in', fig.align='center', message=FALSE, fig.pos='H'>>=

if (!require(tsDyn)) install.packages("tsDyn")

mono = TVECM(datos, lag=8, nthresh = 1, trim=0.05, ngridBeta = 100, ngridTh = 100, plot=TRUE, include=c("const"), common = "All", beta = list(int = c(-0.5,1.5)))

@


<<Modelo restringido>>=
mono_rest = TVECM(datos, lag=8, nthresh = 1, trim=0.05, ngridBeta = 100, ngridTh = 100, plot=TRUE, include=c("const"), common = "All", beta = list(exact = 1))
@


<<>>=

D = 2*(logLik(mono)-logLik(mono_rest))

pchisq(D,1)

@


<<>>=
Hansen = TVECM.HStest(datos, lag=8, ngridTh = 100, trim=0.05, nboot=100, fixed.beta =1)

plot(Hansen)
@

\section{Diagnósticos del modelo no lineal}


<<>>=
layout(matrix(c(1,1,1,1,1,
                2,2,2,2,2,
                3,3,0,4,4),3,5, byrow=TRUE))
plot(ts(residuals(mono_rest)[,1]), main = "Residuos de la ecuación mayorista")
plot(ts(residuals(mono_rest)[,1]), main = "Residuos de la ecuación supermercado")
Acf(residuals(mono_rest)[,1], main = "ACF mayorista")
Acf(residuals(mono_rest)[,2], main = "ACF supermercado")

@


<<fig-5.11,echo=F,fig.cap='Histograma bivariado de los residuos del modelo', out.width='3.5in', out.height='3.5in', fig.align='center', message=FALSE, fig.pos='H'>>=

res = residuals(mono_rest)

x = res[,1]
y = res[,2]

x_c = cut(x,20)
y_c = cut(y,20)

z = table(x_c,y_c)

hist3D(z=z, border="black", contour=TRUE)

@

<<fig-5.12,echo=F,fig.cap='Mapa de calor de los residuos del modelo', out.width='3.5in', out.height='3.5in', fig.align='center', message=FALSE, fig.pos='H'>>=
image2D(z=z, border="black")
@


<<echo = FALSE>>=
errores = data.frame(residuals(mono_rest))
DH.test(errores, names(errores))
vars:::.jb.multi(scale(residuals(mono_rest)), obs = 491, K=2, obj.name = deparse(substitute(mono_rest)))
vars:::.arch.multi(scale(residuals(mono_rest)), lags.multi = 8, K=2, obs = 491, obj.name = deparse(substitute(mono_rest)))

@


\chapter{Conclusiones}
\chapter{Bibliografía}

\hangindent=5em
\hangafter=-2

Ben-Kaabia, M., & Gil Roig, J. M. (2008). Asimetrías en la transmisión de precios en el sector del tomate en España. Economía Agraria y Recursos Naturales, 8(1), 57-82.

Hansen, B. E., & Seo, B. (2002). Testing for two-regime threshold cointegration in vector error-correction models. Journal of econometrics, 110(2), 293-318.

 Pfaff, B. (2008). VAR, SVAR and SVEC models: Implementation within R package vars. Journal of Statistical Software, 27(4), 1-32.


\include{ANEXO}
\end{document}
